---
layout:      post
title:       "自然语言中的信息论"
subtitle:    "代码笔记第二话"
date:        2017-07-16
author:      "XiaoYu"
header-img:  "img/post-code-infotheory.jpg"
catalog:     true
tags:
    - Code
    - Mathematics
    - Theory
---
>这学期学了信息论，心机地做了课代表，不过我是尽职的，当然这门课很有意思，想到以前看的《数学之美》，有所感悟。

# 信息

## 信息是什么

有一个题目是写出消息、信息、信号的含义，这个还是比较明确的，那我会做一个比方。用手机发一份邮件，那别人收到的就是消息，他阅读邮件后得到的就是信息，邮件在传输时，会以电信号、电磁波、光信号的形式通过链路。这就说明了三者的含义。信息一直都在这个宇宙中，但它真正成为一门学科还是20世纪的事情。

信息论的定义：`科普中国` 运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。值得一提的是，它的英文名是 `A Theory of Comunication`。这也表明它与通信是分不开的。

## 信息论之父——Shannon

1948年，香农在贝尔实验室发表的论文《A Mathematical Theory of Communication》一举成为现代信息论研究的开端，原因在于他提出了信息熵的概念，对消息的不确定性进行了衡量。熵指的是*平均自信息量*，也就是集中某个事件出现的平均可能性。
*Definition*
![](http://latex.codecogs.com/gif.latex?H = -\\sum_{i}P_i*log{P_i})
**香农居然还是我讨厌的《数字电路》的理论基础提出者**，但我还是很钦佩他的，他的重视实践、追求完美、永不满足的科学精神是值得我学习的，另外，他的博士论文是关于人类遗传学的，题目是《An Algebra for Theoretical Genetics》，这也表明天才总是可以将各种领域联系到一起，他还是美国哲学学会会员，我也一直认为数理科学的最高处就是哲学，这也是我努力的方向。

# 语言、文字

语言和文字都是信息的载体。

## 自然语言处理

人类很久之前就使用语言进行交流，从一开始的壁画，到楔形文字、象形文字，再到逐渐成形的汉字、英语等语言，经历了几千年的发展，语言和文字都已经基本确定，语言和文字的区别在于一个强调”说“，一个强调“写”。

`科普中国`：自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是一门融语言学、计算机科学、数学于一体的科学。
这里就要提到机器学习了，两者在一定程度上是相互依赖的，后面我想再写一篇这方面的。

自然语言处理的关键是如何让机器“理解”语言，以前的科学家是从语义出发点，也就是说他们不认为理解是要加上引号的，几十年的发展证明这样是错的方向，现在的研究都是从语法出发，即利用语言的统计特性对语言进行量化，使机器能够算出“意义”，机器显然是不能像人一样理解语言的，但可以做的概率上的理解。自然语言处理，即实现人机间自然语言通信，或实现自然语言理解和自然语言生成是十分困难的。造成困难的根本原因是自然语言文本和对话的各个层次上广泛存在的各种各样的歧义性或多义性,现在的工作也就是消除歧义性。

至于它的分类，[微软亚洲研究院](https://www.zhihu.com/question/19895141/answer/149475410)给出了如下介绍：

1. 句法语义分析：对于给定的句子，进行分词、词性标记、命名实体识别和链接、句法分析、语义角色识别和多义词消歧。
2. 信息抽取：从给定文本中抽取重要的信息，比如，时间、地点、人物、事件、原因、结果、数字、日期、货币、专有名词等等。通俗说来，就是要了解谁在什么时候、什么原因、对谁、做了什么事、有什么结果。涉及到实体识别、时间抽取、因果关系抽取等关键技术。
3. 文本挖掘（或者文本数据挖掘）：包括文本聚类、分类、信息抽取、摘要、情感分析以及对挖掘的信息和知识的可视化、交互式的表达界面。目前主流的技术都是基于统计机器学习的。
4. 机器翻译：把输入的源语言文本通过自动翻译获得另外一种语言的文本。根据输入媒介不同，可以细分为文本翻译、语音翻译、手语翻译、图形翻译等。机器翻译从最早的基于规则的方法到二十年前的基于统计的方法，再到今天的基于神经网络（编码-解码）的方法，逐渐形成了一套比较严谨的方法体系。
5. 信息检索：对大规模的文档进行索引。可简单对文档中的词汇，赋之以不同的权重来建立索引，也可利用1，2，3的技术来建立更加深层的索引。在查询的时候，对输入的查询表达式比如一个检索词或者一个句子进行分析，然后在索引里面查找匹配的候选文档，再根据一个排序机制把候选文档排序，最后输出排序得分最高的文档。
6. 问答系统： 对一个自然语言表达的问题，由问答系统给出一个精准的答案。需要对自然语言查询语句进行某种程度的语义分析，包括实体链接、关系识别，形成逻辑表达式，然后到知识库中查找可能的候选答案并通过一个排序机制找出最佳的答案。
7. 对话系统：系统通过一系列的对话，跟用户进行聊天、回答、完成某一项任务。涉及到用户意图理解、通用聊天引擎、问答引擎、对话管理等技术。此外，为了体现上下文相关，要具备多轮对话能力。同时，为了体现个性化，要开发用户画像以及基于用户画像的个性化回复。

在我们日常生活中，接触到的语音助手如`Siri`，搜索引擎的分词都是自然语言处理的产物。

## 输入法中的信息论

中文输入法已经做的很好了，各家产品现在也都是在UX上下功夫，就手机输入法来说，有搜狗、百度、讯飞等。在触屏时代，虚拟键盘成为了主要的交互工具，前段时间听一个博客节目，嘉宾是百度的设计师，他说九宫格键盘的存在是有一定道理的，但是他没有具体说明，我想在信息论的角度看一下这个问题。

常用的汉字有2500多个，次常用汉字则有1000多个，像老舍的《骆驼祥子》就用了2313个不同的汉字，那来看一下打出一个汉字平均要按多少次。
先看26键，假设有2048个汉字且出现概率相同，则
![](http://latex.codecogs.com/gif.latex?\log{2048}=11)
![](http://latex.codecogs.com/gif.latex?\log{26}=4.7)
那么打一个汉字需要按11/4.7=2.34下，但这还不考虑汉字的组合以及上下文相关性，如果考虑的话，汉字的信息熵大概是8比特，这样就只需要按1.7次按键了，当然这是不可能达到的，因为汉字是用拼音区别的，前面的4.7则是对字母的理论编码，显然实际中是无法做到的。我拿出了一本《新华字典》对所有的拼音进行了统计，汉字的平均拼音长为2.98，也就是要按2.98次键盘，如果考虑输入法的优化，平均输入一个汉字应该要按2.5次或更少。
再看我平常使用的九宫格输入法，我对日常打字进行了纪录，发现平均输入一个汉字仅需按两次（不考虑点选），一般最后出现的字是不需要完整打出来的。这样看来两者速度上是相同的，如果把拼音全部打出来的话，
但事实是打字时我们的手是需要移动的，在小屏幕上，26键带来的问题是误触，所以说九宫格会稍快一些。

# 写在最后

生活中有很多的事情都可以用数学模型去分析，这也是人工智能的出发点吧，前段时间看到一种输入法叫双拼输入法，接下来我要研究研究。


